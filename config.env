# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=auto

# Model Selection:
# - "auto" = Automatically detect and select the best available model
# - "tinyllama" = Fast, good analysis (8-12s)
# - "phi" = Ultra-fast, basic analysis (3-5s) 
# - "qwen2.5:0.5b" = Very fast, good analysis (5-8s)
# - "gemma2:2b" = Fast, balanced performance (6-10s)
# - "llama2:7b" = Moderate speed, high quality (10-20s)
# - "llama2:13b" = Slower, excellent quality (15-30s)
# - "llama2:70b" = Slow, best quality (30-60s)

# Performance Optimization
# The bot will automatically select the fastest available model
# based on your installed models and performance preferences
MAX_RESPONSE_LENGTH=500

# Security Configuration
ENABLE_INPUT_VALIDATION=true
MAX_PROMPT_LENGTH=1000
ALLOWED_CHARACTERS=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,!?@#$%^&*()_+-=[]{}|;:'"<>?/\\

# Logging Configuration
LOG_LEVEL=info
LOG_TO_FILE=true
LOG_TO_CONSOLE=true